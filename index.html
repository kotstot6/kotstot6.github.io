<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Kyle Otstot · Digital Resume</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Saira+Extra+Condensed:500,700" rel="stylesheet" type="text/css" />
        <link href="https://fonts.googleapis.com/css?family=Muli:400,400i,800,800i" rel="stylesheet" type="text/css" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
        <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script>
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-dark bg-primary fixed-top" id="sideNav">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">
                <span class="d-block d-lg-none">Kyle Otstot · Digital Resume</span>
                <span class="d-none d-lg-block"><img class="img-fluid img-profile rounded-circle mx-auto mb-2" src="assets/img/profile3.jpg" alt="..." /></span>
            </a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation"><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#about">About</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#education">Education</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#experience">Experience</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#projects">Projects</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#skills">Skills</a></li>
                    <li class="nav-item"><a class="nav-link js-scroll-trigger" href="#awards">Awards</a></li>
                </ul>
            </div>
        </nav>
        <!-- Page Content-->
        <div class="container-fluid p-0">
            <!-- About-->
            <section class="resume-section" id="about">
                <div class="resume-section-content">
                    <h1 class="mb-0">
                        Kyle
                        <span class="text-primary">Otstot</span>
                        &#128104;&#8205;&#128300;
                    </h1>
                    <div class="subheading mb-5">
                        Incoming Machine Learning Engineer @ TikTok · Mountain View, CA ·
                        <a href="mailto:kotstot@asu.edu">kotstot@asu.edu</a>
                    </div>
                    <p class="lead mb-5">
                      Hello world &#x1F44B; welcome to my website! I am 23 years old and recently graduated from Arizona State University with a MS degree in computer science.
                      Through my research, coursework, and personal projects, I have gained experience in a range of machine learning (ML) fields, including <em>computer vision</em>, <em>natural language processing</em>, <em>recommender systems</em>, and <em>time-series forecasting</em>.
                      Recently, I worked for Spotify as a Machine Learning Engineer Intern, where I developed a new dataset filtering technique that improved the online performance of a model responsible for playlist track recommendation. I also worked as a Graduate Research Assistant for Sankar Lab of ASU, where we curated robust methods for the common ML security problems of domain adaptation and generative adversarial network (GAN) training instability.
                      <em><b>Next month, I will join TikTok as a Machine Learning Engineer in Mountain View, California!</b></em>
                     Hope you enjoy my website, and don't forget to connect with me on social media! (links below)
                      <em>[Last updated: 12/23]</em>
                    </p>
                    <div class="social-icons">
                      <a class="social-icon" href="work/resume.pdf" target="_blank"><i class="fab fa-readme"></i></a>
                        <a class="social-icon" href="https://www.linkedin.com/in/kyle-otstot-a0a0ab241/" target="_blank"><i class="fab fa-linkedin-in"></i></a>
                        <a class="social-icon" href="https://github.com/kotstot6" target="_blank"><i class="fab fa-github"></i></a>
                        <!--<a class="social-icon" href="#!"><i class="fab fa-twitter"></i></a>-->
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Education-->
            <section class="resume-section" id="education">
                <div class="resume-section-content">
                    <h2 class="mb-5">Education &#x1F4DA;</h2>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Master of Science, Computer Science &#x1F5A5;</h3>
                            <div class="subheading mb-3">Arizona State University</div>

                            <p><b>Thesis:</b>
                              <a class="scroll-link" href="#masters-thesis">Towards Addressing GAN Training Instabilities: Dual-Objective GANs with Tunable Parameters
                                <svg class="bi bi-arrow-up-right-square" width="15px" height="15px" viewBox="0 0 16 16" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
                                  <path fill-rule="evenodd" d="M14 1H2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V2a1 1 0 0 0-1-1zM2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2z"></path>
                                  <path fill-rule="evenodd" d="M10.5 5h-4a.5.5 0 0 0 0 1h2.793l-4.147 4.146a.5.5 0 0 0 .708.708L10 6.707V9.5a.5.5 0 0 0 1 0v-4a.5.5 0 0 0-.5-.5z"></path>
                                </svg></a>
                            </p>

                            <p><b>Key Courses:</b> Data Mining, Statistical Machine Learning, Semantic Web Mining, Data Visualization, ML Security & Fairness, Cloud Computing</p>

                            <p><b>GPA:</b> 4.0</p>

                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">August 2022 - July 2023</span></div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Bachelor of Science, Computer Science &#x1F4BB; &#x1F393;</h3>
                            <div class="subheading mb-3">Barrett, the Honors College - ASU</div>
                            <p>
                              <b>Thesis:</b> <a class="scroll-link" href="#honors-thesis">A Graph-Based Machine Learning Approach to Realistic Traffic Volume Generation
                                  <svg class="bi bi-arrow-up-right-square" width="15px" height="15px" viewBox="0 0 16 16" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
                    								<path fill-rule="evenodd" d="M14 1H2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V2a1 1 0 0 0-1-1zM2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2z"></path>
                    								<path fill-rule="evenodd" d="M10.5 5h-4a.5.5 0 0 0 0 1h2.793l-4.147 4.146a.5.5 0 0 0 .708.708L10 6.707V9.5a.5.5 0 0 0 1 0v-4a.5.5 0 0 0-.5-.5z"></path>
                                  </svg></a>
                            </p>

                            <p><b>Awards:</b> Recipient of <a class="scroll-link" href="#cse-scholarship">2021-22 William E. Lewis Excellence in Computer Science Engineering Scholarship
                              <svg class="bi bi-arrow-up-right-square" width="15px" height="15px" viewBox="0 0 16 16" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
                                <path fill-rule="evenodd" d="M14 1H2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V2a1 1 0 0 0-1-1zM2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2z"></path>
                                <path fill-rule="evenodd" d="M10.5 5h-4a.5.5 0 0 0 0 1h2.793l-4.147 4.146a.5.5 0 0 0 .708.708L10 6.707V9.5a.5.5 0 0 0 1 0v-4a.5.5 0 0 0-.5-.5z"></path>
                              </svg>
                            </a> and ASU President's Scholarship, Summa Cum Laude, Dean's List (2019-2022)</p>

                            <p><b>Key Courses:</b> Object-Oriented Programming, Digital Design Fundamentals, Intro to Programming Languages, Assembly Language, Data Structures & Algorithms, Software Development, Information Assurance, Principles of Programming Languages, Operating Systems, Theoretical Computer Science, Computer Networks, Social Media Mining</p>

                            <p><b>GPA:</b> 4.0</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">August 2019 - May 2022</span></div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Bachelor of Science, Mathematics &#x2716; 	&#x2797;</h3>
                            <div class="subheading mb-3">Barrett, the Honors College - ASU</div>

                            <p><b>Awards:</b> <a class="scroll-link" href="#phi-beta-kappa">Phi Beta Kappa Inductee
                              <svg class="bi bi-arrow-up-right-square" width="15px" height="15px" viewBox="0 0 16 16" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
                                <path fill-rule="evenodd" d="M14 1H2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V2a1 1 0 0 0-1-1zM2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2z"></path>
                                <path fill-rule="evenodd" d="M10.5 5h-4a.5.5 0 0 0 0 1h2.793l-4.147 4.146a.5.5 0 0 0 .708.708L10 6.707V9.5a.5.5 0 0 0 1 0v-4a.5.5 0 0 0-.5-.5z"></path>
                              </svg>
                            </a>, <a class="scroll-link" href="#wexler-dinner">Wexler Mathematical Sciences Senior Dinner Invitee
                              <svg class="bi bi-arrow-up-right-square" width="15px" height="15px" viewBox="0 0 16 16" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
                                <path fill-rule="evenodd" d="M14 1H2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V2a1 1 0 0 0-1-1zM2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2z"></path>
                                <path fill-rule="evenodd" d="M10.5 5h-4a.5.5 0 0 0 0 1h2.793l-4.147 4.146a.5.5 0 0 0 .708.708L10 6.707V9.5a.5.5 0 0 0 1 0v-4a.5.5 0 0 0-.5-.5z"></path>
                              </svg>
                            </a>, Summa Cum Laude, Dean's List (2019-2022)</p>

                            <p><b>Key Courses:</b> Discrete Math Structures, Applied Linear Algebra, Mathematical Structures, Advanced Calculus, Advanced Linear Algebra, Graph Theory, Linear Optimization, Scientific Computing, Computational Methods for Image Processing </p>

                            <p><b>GPA:</b> 4.0</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">August 2019 - May 2022</span></div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">International Baccalaureate (IB) Diploma &#x1F4DC;</h3>
                            <div class="subheading mb-3">Desert Mountain High School</div>
                            <p><b>Awards:</b> Salutatorian (rank 2/536), AP national scholar, IB diploma recipient</p>
                            <p><b>GPA:</b> 4.92 &nbsp;&nbsp; <b>SAT:</b> 1580</p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">August 2015 - May 2019</span></div>
                    </div>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Experience-->
            <section class="resume-section" id="experience">
                <div class="resume-section-content">
                    <h2 class="mb-5">Experience &#128104;&#8205;&#128187;</h2>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                      <div class="flex-grow-1">
                          <h3 class="mb-0">Machine Learning Engineer Intern &#127926;</h3>
                          <div class="subheading mb-3">Spotify - Personalization Mission</div>
                          <p>For this internship, I worked on improving a deep learning classifier that contributes to the "personalization" of playlists, i.e. scoring of tracks tailored to the user.</p>
                          <ul>
                            <li>I proposed a novel dataset filtering method to improve the aforementioned classification model, which increased percentage of users with long listens by 0.7%.</li>
                            <li>
                              In doing so, I designed an experiment for Bayesian-optimizing the filtering method, and created a Ray pipeline that reduced the model training runtime from hours to seconds.
                            </li>
                            <li>Additionally, I contributed to a Kubeflow training pipeline deployed in production for an A/B test, which proved to be a successful test (see first bullet).</li>
                          </ul>
                      </div>
                      <div class="flex-shrink-0"><span class="text-primary">June 2023 - September 2023</span></div>
                  </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Graduate Research Assistant &#128104;&#8205;&#128300;</h3>
                            <div class="subheading mb-3">Sankar Lab - Arizona State University</div>
                            <p>Having completed my Bachelor's degrees in Spring 2022, I continued to work under Dr. Lalitha Sankar in her lab with a new project on GAN training stability.</p>
                            <ul>
                              <li>The summer before graduate school, I began a new research project with other members in Sankar Lab, which was funded for me by the <b><em>2022 SURI program</em></b>. In this project, we focus on the use of alternative objective functions (i.e., not binary cross entropy) for generative adversarial network (GAN) training in order to help stabilize convergence and lessen the network's performance dependency on random weight initializations. In doing so, we consider <em>alpha-loss</em>, a family of tunable loss functions that encapsulate cross entropy loss and other notable losses. Over the summer, we were able to empirically (and a bit theoretically) show that some instances of alpha-loss help reduce the common GAN training threats of vanishing gradients, exploding gradients, and mode collapse. Experiments were primarily done on 2D toy datasets with fully-connected generator and discriminator models.</li>
                              <li>At the beginning of the 2022-2023 school year, I was officially appointed as an ASU <b><em>Graduate Research Assistant (GRA)</em></b> in order to continue my research on GAN training instabilities. Having first observed performance gains on the 2D toy datasets, we then moved to the benchmark image datasets of Stacked MNIST, Celeb-A, and LSUN.
                                In both cases, we consider the use of deep convolutional generative adversarial nets (DCGANs) with state-of-the-art optimization (Adam) and objective functions (least squares & alpha-loss).
                                As a result, I co-authored the paper titled
                                <a class="scroll-link" href="#alpha-gan"><em>\((\alpha_{D}, \alpha_{G})\)-GANs: Addressing GAN Training Instabilities via Dual Objectives</em>
                                  <svg class="bi bi-arrow-up-right-square" width="15px" height="15px" viewBox="0 0 16 16" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
                                  <path fill-rule="evenodd" d="M14 1H2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V2a1 1 0 0 0-1-1zM2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2z"></path>
                                  <path fill-rule="evenodd" d="M10.5 5h-4a.5.5 0 0 0 0 1h2.793l-4.147 4.146a.5.5 0 0 0 .708.708L10 6.707V9.5a.5.5 0 0 0 1 0v-4a.5.5 0 0 0-.5-.5z"></path>
                                </svg></a>, which was accepted into the 2023 IEEE International Symposium on Information Theory (ISIT) conference and New Frontiers in Adversarial Machine Learning workshop at the 2023 International Conference on Machine Learning (ICML).
                              </li>
                            </ul>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">June 2022 - May 2023</span></div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Undergraduate Research Intern &#129514;</h3>
                            <div class="subheading mb-3">Sankar Lab - Arizona State University</div>
                            <p>
                              At the end of the Spring 2021 semester, I began my undergraduate research under the supervision of Dr. Lalitha Sankar and her ASU lab. Our work primarily focused on the robustness of (classification) loss functions under settings of train label noise.
                            </p>
                            <ul>
                              <li>In the summer of 2021, I was accepted into <b><em>ASU's Summer Undergraduate Research Initiative (SURI)</em></b> program, which funded my work with Sankar Lab. Over the 8 week program, I learned how to design image classification experiments with PyTorch and ASU's shared cluster environment (Agave); specifically, I implemented experiments with benchmark clean/corrupted datasets (CIFAR-10/100, CIFAR-10/100-C), deep model architectures (WideResNet), state-of-the-art optimization techniques (cosine learning rate annealing), and robust loss functions (alpha loss, NCE+RCE, focal loss). At the end of the program, I compiled and presented my work titled <a class="scroll-link" href="#suri-presentation"><em>Robustness of a Tunable Loss Function Family on Corrupted Datasets</em>
                                <svg class="bi bi-arrow-up-right-square" width="15px" height="15px" viewBox="0 0 16 16" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
                                  <path fill-rule="evenodd" d="M14 1H2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V2a1 1 0 0 0-1-1zM2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2z"></path>
                                  <path fill-rule="evenodd" d="M10.5 5h-4a.5.5 0 0 0 0 1h2.793l-4.147 4.146a.5.5 0 0 0 .708.708L10 6.707V9.5a.5.5 0 0 0 1 0v-4a.5.5 0 0 0-.5-.5z"></path>
                                </svg>
                              </a>, which can be found on this website.</li>
                              <li>For the 2021-2022 school year, I was awarded a <b><em>Research Experience for Undergraduates (REU)</em></b> position funded by the <em>National Science Foundation (NSF)</em> in order to continue my research with Sankar Lab. During this time, we built on our work from the summer by developing a method (named <em>AugLoss</em>) that combines the use of data augmentation and robust loss functions in order to simultaneously mitigate the threats of test-time distribution shifts and train-time noisy labeling of the data. We show that our method can outperform previous state-of-the-art methods on (feature + label) corrupted versions of the benchmark CIFAR-10/100 datasets. As a result, I first-authored the paper titled <a class="scroll-link" href="#augloss"><em>AugLoss: A Learning Methodology for Real-World Dataset Corruption</em>
                                <svg class="bi bi-arrow-up-right-square" width="15px" height="15px" viewBox="0 0 16 16" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
                                  <path fill-rule="evenodd" d="M14 1H2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V2a1 1 0 0 0-1-1zM2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2z"></path>
                                  <path fill-rule="evenodd" d="M10.5 5h-4a.5.5 0 0 0 0 1h2.793l-4.147 4.146a.5.5 0 0 0 .708.708L10 6.707V9.5a.5.5 0 0 0 1 0v-4a.5.5 0 0 0-.5-.5z"></path>
                                </svg>
                              </a>, which was accepted into the <em>Principles of Distribution Shift</em> workshop at the <em>International Conference on Machine Learning (ICML)</em>. In July 2022, I presented our work at this ICML workshop in Baltimore, Maryland.</li>
                            </ul>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">April 2021 - June 2022</span></div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Undergraduate Teaching Assistant 	&#x1F468;&#x200D;&#x1F3EB;</h3>
                            <div class="subheading mb-3">Fulton Schools of Engineering - ASU</div>
                            <p>For the Fall 2020, Spring 2021, and Fall 2021 semesters, I worked as a TA for the <b><em>Probability & Statistics for Engineers (IEE 380)</em></b> course under Dr. Michael Clough in ASU's Fulton Schools of Engineering. This course covers the fundamentals of probability theory, descriptive statistics, one/two sample hypothesis testing, simple/multiple linear regression, and statistical quality control.
                              As a TA, my primary responsibilities included creating/presenting exam reviews (see this <a href="work/midterm_review.pdf" target="_blank">midterm review</a> and <a href="work/final_review.pdf" target="_blank">final exam review</a> for examples), holding semi-weekly office hours, monitoring discussion boards, and proctoring exams. Additionally, I developed a website called <a class="scroll-link" href="#hypothetest"><em>Hypothetest</em>
                                <svg class="bi bi-arrow-up-right-square" width="15px" height="15px" viewBox="0 0 16 16" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
                                  <path fill-rule="evenodd" d="M14 1H2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V2a1 1 0 0 0-1-1zM2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2z"></path>
                                  <path fill-rule="evenodd" d="M10.5 5h-4a.5.5 0 0 0 0 1h2.793l-4.147 4.146a.5.5 0 0 0 .708.708L10 6.707V9.5a.5.5 0 0 0 1 0v-4a.5.5 0 0 0-.5-.5z"></path>
                                </svg>
                              </a> that aims to help students solve and visualize their two-sample hypothesis test problems.
                            </p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">August 2020 - December 2021</span></div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Instructional Aide &#x1F392;</h3>
                            <div class="subheading mb-3">School of Mathematical & Statistical Sciences - ASU</div>
                            <ul>
                              <li>In the Summer 2021 semester, I worked for one <b><em>Calculus for Engineers II (MAT 266)</em></b> course in ASU's School of Mathematical & Statistical Sciences. My primary responsibilities included holding office hours and answering questions on the discussion board.</li>
                              <li>Also in the Summer 2021 semester, I worked for one <b><em>Elementary Linear Algebra (MAT 242)</em></b> course of the same school. My primary responsibilities included monitoring and answering questions on the discussion board.</li>
                              <li>Lastly, between the Spring 2021 and Summer 2021 semesters, I worked for two <b><em>Math for Business Analysis (MAT 211)</em></b> courses of the same school. My primary responsibilities included holding office hours and answering questions on the discussion board.</li>
                            </ul>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">March 2021 - December 2021</span></div>
                    </div>

                    <div class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                            <h3 class="mb-0">Student Grader &#x1F4DD;</h3>
                            <div class="subheading mb-3">Arizona State University</div>
                            <!--<p>
                              Between the semesters of Summer 2021 and Fall 2021, I graded for 7 <em>Discrete Math Structures (MAT 243)</em> courses in ASU's College of Liberal Arts & Sciences. My primary responsibilities included holding office hours, as well as grading homework assignments and quizzes.
                              Additionally, I graded for one Fall 2021 semester of the <em>Intro to Theoretical Computer Science (CSE 355)</em> course in ASU's School of Computing & Augmented Intelligence. My primary responsibilities included holding office hours, as well as grading recitations and homework assignments.
                            </p>-->
                            <ul>
                              <li>Between the semesters of Summer 2021 and Fall 2021, I graded for 7 <b><em>Discrete Math Structures (MAT 243)</em></b> courses in ASU's School of Mathematical & Statistical Sciences. My primary responsibilities included holding office hours, as well as grading homework assignments and quizzes.</li>
                              <li>Additionally, I graded for one Fall 2021 semester of the <b><em>Intro to Theoretical Computer Science (CSE 355)</em></b> course in ASU's School of Computing & Augmented Intelligence. My primary responsibilities included holding office hours, as well as grading recitations and homework assignments.</li>
                            </ul>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">June 2021 - December 2021</span></div>
                    </div>

                </div>
            </section>
            <hr class="m-0" />
            <!-- Interests-->
            <section class="resume-section" id="projects">
                <div class="resume-section-content">
                    <h2 class="mb-5">Projects &#x1F4CA;</h2>

                    <div id="masters-thesis" class="d-flex flex-column flex-md-row justify-content-between mb-5">
                      <div class="flex-grow-1">
                          <img style="max-height:250px;max-width:90%;margin: 0px 0px 10px 0px;"src="assets/img/masters_thesis.png">
                          <h3 class="mb-0">Towards Addressing GAN Training Instabilities: Dual-Objective GANs with Tunable Parameters &#127899;  &#129295;</h3>
                          <div class="subheading mb-3">Robust Generative Models, Convolutional Nets, Fréchet Inception Distance</div>
                          <p>
                            This thesis introduces the \((\alpha_{D}, \alpha_{G})\)-GAN, a parameterized class of dual-objective GANs, as an alternative approach to the standard vanilla GAN.
                            The \((\alpha_{D}, \alpha_{G})\)-GAN formulation, inspired by \(\alpha\)-loss, allows practitioners to tune the parameters \((\alpha_{D}, \alpha_{G}) \in [0,\infty)^{2}\) to provide a more stable training process. The objectives for the generator and discriminator in \((\alpha_{D}, \alpha_{G})\)-GAN are derived, and the advantages of using these objectives are investigated. In particular, the optimization trajectory of the generator is found to be influenced by the choice of \(\alpha_{D}\) and \(\alpha_{G}\).
                            Empirical evidence is presented through experiments conducted on various datasets, including the 2D Gaussian Mixture Ring, Celeb-A image dataset, and LSUN Classroom image dataset. Performance metrics such as mode coverage and Fréchet Inception Distance (FID) are used to evaluate the effectiveness of the \((\alpha_{D}, \alpha_{G})\)-GAN compared to the vanilla GAN and state-of-the-art Least Squares GAN (LSGAN). The experimental results demonstrate that tuning \(\alpha_{D} < 1\) leads to improved stability, robustness to hyperparameter choice, and competitive performance compared to LSGAN.
                          </p>
                          <p><a href="work/masters_thesis_paper.pdf" target="_blank">Paper</a> &nbsp; · &nbsp; <a href="work/masters_thesis_presentation.pdf" target="_blank">Presentation</a> &nbsp; · &nbsp; <a href="https://github.com/SankarLab/AlphaGan-Papers-Results" target="_blank">Github</a></p>
                      </div>
                      <div class="flex-shrink-0"><span class="text-primary">February 2023 - June 2023</span></div>
                  </div>

                    <div id="alpha-gan" class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <img style="max-height:250px;max-width:90%;margin: 0px 0px 10px 0px;"src="assets/img/alphagan.png">
                            <h3 class="mb-0">\((\alpha_{D}, \alpha_{G})\)-GANs: &#9996; &#x2705; Addressing GAN Training Instabilities via Dual Objectives</h3>
                            <div class="subheading mb-3">Robust Generative Models, Convolutional Nets, Fréchet Inception Distance</div>
                            <p>
                              In an effort to address the training instabilities of GANs, we introduce a class of dual-objective GANs with different value functions (objectives) for the generator (\(G\)) and discriminator (\(D\)).
                              In particular, we model each objective using \(\alpha\)-loss, a tunable classification loss, to obtain \((\alpha_{D}, \alpha_{G})\)-GANs, parameterized by \((\alpha_{D}, \alpha_{G}) \in [0, \infty)^{2}\).
                              For sufficiently large number of samples and capacities for \(G\) and \(D\), we show that the resulting non-zero sum game simplifies to minimizing an \(f\)-divergence under appropriate conditions on \((\alpha_{D}, \alpha_{G})\).
                              In the finite sample and capacity setting, we define estimation error to quantify the gap in the generator's performance relative to the optimal setting with infinite samples and obtain upper bounds on this error, showing it to be order optimal under certain conditions.
                              Finally, we highlight the value of tuning \((\alpha_{D}, \alpha_{G})\) in alleviating training instabilities for the synthetic 2D Gaussian mixture ring and the Stacked MNIST datasets.
                            </p>
                            <p><a href="https://arxiv.org/abs/2302.14320" target="_blank">Paper</a> &nbsp; · &nbsp; <a href="work/alpha_gan_poster.pdf" target="_blank">Poster</a> &nbsp; · &nbsp; <a href="https://github.com/SankarLab/AlphaGan-Papers-Results" target="_blank">Github</a></p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">November 2022 - January 2023</span></div>
                    </div>

                    <div id="disconet" class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <img style="max-height:250px;max-width:90%;margin: 0px 0px 10px 0px;"src="assets/img/disconet.png">
                            <h3 class="mb-0"><em>DiscoNet:</em> &#x1F57A; &#x1F578; Towards Mitigating Shortcut Learning with Cross-Domain Regularization</h3>
                            <div class="subheading mb-3">Domain Adaptation, Shortcut Learning, Generative Adversarial nets</div>
                            <p>Deep learning methods have achieved remarkable advancements in the task of image classification, but progress has been particularly limited in settings of out-of-distribution testing.
                              As a result, domain adaptation methods have been proposed to robustify the model against unforeseen data distribution shifts; however, we find that these methods are inherently vulnerable to
                              <em>shortcut learning</em>, a phenomenon where models learn on spurious cues instead of the true image semantics. In this project, we propose a new domain adaptation method, <em>DiscoNet</em>, that learns
                              a cross-domain mapping between the source and target domains in order to embed each dataset similarly during training. We find that our approach is robust to shortcut learning, which is demonstrated with our
                              novel dataset called <em>Striped MNIST</em>. Overall, we hope to underscore the importance of finding a relationship between source and target datasets when curating new domain adaptation solutions.
                            </p>
                            <p><a href="work/disconet.pdf" target="_blank">Paper</a> &nbsp; · &nbsp; <a href="https://github.com/kotstot6/DiscoNet" target="_blank">Github</a></p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">October 2022 - December 2022</span></div>
                    </div>

                    <div id="accident-analyzer" class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                            <img style="max-height:300px;max-width:90%;margin: 0px 0px 10px 0px;"src="assets/img/accident_analyzer.png">
                            <h3 class="mb-0"><em>Accident-Analyzer:</em> &#x1F697; &#x1F5FA; Understanding Vehicle Accident Patterns in the United States</h3>
                            <div class="subheading mb-3">Data Visualization, D3 Javascript library</div>
                            <p>In this project, we re-imagine <em>CrimAnalyzer</em>- a visualization assisted analytic tool for crimes in São Paulo- in the context of traffic accidents, ultimately producing <em>Accident-Analyzer</em>. In doing so, we explore the spatio-temporal patterns of traffic accidents across the United States from 2016 to 2021. The <em>Accident-Analyzer</em> system allows for users to identify local hotspots, visualize accident trends over time, and filter the data by key weather categories in real-time. The visualization was primarily created with the D3 and Leaflet JS libraries, the dataset preprocessing was done with Python, and the data is stored/accessed via MySQL database.</p>
                            <p><a href="work/accident_analyzer.pdf" target="_blank">Paper</a> &nbsp; · &nbsp; <a href="work/accident_poster.pdf" target="_blank">Poster</a> &nbsp; · &nbsp;  <a href="https://github.com/kotstot6/AccidentAnalyzer" target="_blank">Github</a></p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">September 2022 - December 2022</span></div>
                    </div>

                    <div id="movie-recommendation" class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                          <img style="max-height:250px;max-width:90%;margin: 0px 0px 10px 0px;"src="assets/img/movie_rec.png">
                            <h3 class="mb-0">A Survey of Deep Learning-Based Movie Recommendation Systems &#x1F3AC;</h3>
                            <div class="subheading mb-3">Recommendation Systems, Deep Learning</div>
                            <p>
                              In this work, we provide a comprehensive and systematic analysis of current research methods on deep learning-based movie recommendation systems, specifically with empirical evaluation on the benchmark <em>MovieLens</em> dataset. We also provide a detailed taxonomy and summaries of state-of-the-art algorithms, providing a perspective on the future trends and research challenges of deep learning recommendation systems.
                            </p>
                            <p><a href="work/movie_rec_paper.pdf" target="_blank">Paper</a> &nbsp; · &nbsp; <a href="work/movie_rec_presentation.pdf" target="_blank">Presentation</a> &nbsp; · &nbsp;  <a href="https://github.com/kotstot6/MovieRecommendation" target="_blank">Github</a></p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">September 2022 - December 2022</span></div>
                    </div>

                    <div id="evasion-attacks" class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                          <img style="max-height:250px;max-width:90%;margin: 0px 0px 10px 0px;"src="assets/img/evasion_attack.png">
                            <h3 class="mb-0">Non-Targeted White-Box Evasion Attacks on the Fashion MNIST dataset &#x1F510;&#x1F457;</h3>
                            <div class="subheading mb-3">Adversarial learning, evasion attacks, deep learning</div>
                            <p>In this project, I train a convolutional neural net (CNN) with a <em>LeNet-5</em> architecture on the Fashion MNIST dataset, which achieves a 99.3% validation accuracy. Then, I implement two white-box evasion attacks– namely, fast gradient sign method (FGSM) and projected gradient descent (PGD)– in order to create adversarial examples that closely resemble the original Fashion MNIST image, yet dramatically alter the classification output of the CNN. This project underscores the vulnerability of the standard deep learning classification algorithm to carefully-crafted adversarial images.</p>
                            <p><a href="work/evasion.pdf" target="_blank">Report</a> &nbsp; · &nbsp; <a href="https://github.com/kotstot6/EvasionAttacks" target="_blank">Github</a></p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">September 2022 - September 2022</span></div>
                    </div>

                    <div id="wells-fargo" class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                          <img style="max-height:250px;max-width:90%;margin: 0px 0px 10px 0px;"src="assets/img/wells_fargo.png">
                            <h3 class="mb-0">Building Robust and Accurate Transaction Classifiers with Deep Transfer Learning &#x1F4B0;&#x2705;</h3>
                            <div class="subheading mb-3">NLP, Gradient Boosting, Deep Transformers, Web Scraping</div>
                            <p>
                              In this work, I develop a solution for the task of transaction categorization, specifically with the
dataset provided by the 2022 Wells Fargo Campus Analytics Challenge. Overall, I achieve a few
noteworthy contributions, including the engineering of two attributes responsible for improvement
in ML performance, development of a word clustering algorithm that helps the practitioner better understand the relationships between words across categories, and design of a high-performing
classifier of 88% test accuracy using deep transfer learning and state-of-the-art optimization techniques.
                            </p>
                            <p><a href="work/wells_fargo.pdf" target="_blank">Paper</a> &nbsp; · &nbsp; <a href="https://github.com/kotstot6/WellsFargoChallenge" target="_blank">Github</a></p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">June 2022 - July 2022</span></div>
                    </div>

                    <div id="wordlenet" class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                          <img style="max-height:250px;max-width:90%;margin: 0px 0px 10px 0px;"src="assets/img/wordlenet.png">
                            <h3 class="mb-0"><em>WordleNet:</em> &#x1F4F1; Training a Recurrent Neural Network to Play the game "Wordle"</h3>
                            <div class="subheading mb-3">Recurrent Neural Nets, Deep Learning</div>
                            <p></p>
                            <p><a href="">Article</a> (Coming soon) &nbsp; · &nbsp; <a href="https://github.com/kotstot6/WordleNet" target="_blank">Github</a></p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">June 2022 - June 2022</span></div>
                    </div>

                    <div id="honors-thesis" class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                          <img style="max-height:250px;max-width:90%;margin: 0px 0px 10px 0px;"src="assets/img/honors_thesis.png">
                            <h3 class="mb-0">A Graph-Based Machine Learning Approach to Realistic Traffic Volume Generation &#x1F6A6; &#x1F3D9;</h3>
                            <div class="subheading mb-3">Machine Learning, Data Visualization, Statistical Analysis</div>
                            <p>
                              In this work, we explore the potential for realistic and accurate generation of hourly traffic volume with machine learning (ML), using the ground-truth data of Manhattan road segments collected by the New York State Department of Transportation (NYSDOT). Specifically, we address the following question– can we develop a ML algorithm that generalizes the existing NYSDOT data to all road segments in Manhattan?– by introducing a supervised learning task of multi-output regression, where ML algorithms use road segment attributes to predict hourly traffic volume. We consider four ML algorithms– K-Nearest Neighbors, Decision Tree, Random Forest, and Neural Network– and hyperparameter tune by evaluating the performances of each algorithm with 10-fold cross validation. We also provide insight into the quantification of “trustworthiness” in a model, followed by brief discussions on interpreting model performance, suggesting potential project improvements, and identifying the biggest takeaways.
                            </p>
                            <p><a href="work/honors_thesis.pdf" target="_blank">Paper</a> &nbsp; · &nbsp; <a href="work/thesis_defense.pdf" target="_blank">Presentation</a> &nbsp; · &nbsp; <a href="https://github.com/kotstot6/TrafficML" target="_blank">Github</a></p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">December 2021 - May 2022</span></div>
                    </div>

                    <div id="augloss" class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                          <img style="max-height:250px;max-width:90%;margin: 0px 0px 10px 0px;"src="assets/img/augloss.png">
                            <h3 class="mb-0"><em>AugLoss:</em> &#x1F326; &#x1F50D; A Learning Methodology for Real-World Dataset Corruption</h3>
                            <div class="subheading mb-3">Domain Adaptation, Robust Loss Functions, Data Augmentation</div>
                            <p>
                              Deep learning models achieve great successes in many domains, but increasingly face safety and robustness concerns, including noisy labeling in the training stage and feature distribution shifts in the testing stage. Previous works made significant progress in addressing these problems, but the focus has
                              largely been on developing solutions for only one problem at a time. For
                              example, recent work has argued for the use of tunable robust loss functions to mitigate label noise, and data augmentation to
                              combat distribution shifts. As a step towards addressing both problems
                              simultaneously, we introduce <em>AugLoss</em>, a simple but effective methodology that achieves robustness against both train-time noisy labeling and
                              test-time feature distribution shifts by unifying data augmentation and
                              robust loss functions. We conduct comprehensive experiments in varied
                              settings of real-world dataset corruption to showcase the gains achieved
                              by <em>AugLoss</em> compared to previous state-of-the-art methods.
                            </p>
                            <p><a href="https://arxiv.org/abs/2206.02286" target="_blank">Paper</a> &nbsp; · &nbsp; <a href="work/augloss_slides.pdf" target="_blank">Presentation</a> &nbsp; · &nbsp; <a href="work/augloss_poster.pdf" target="_blank">Poster</a> &nbsp; · &nbsp; <a href="https://github.com/SankarLab/AugLoss" target="_blank">Github</a></p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">September 2021 - May 2022</span></div>
                    </div>

                    <div id="fact-checker" class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                          <img style="max-height:250px;max-width:90%;margin: 0px 0px 10px 0px;"src="assets/img/smm.png">
                            <h3 class="mb-0">Building a Fact-Checked Article Classifier with Naive Bayes... and more! &#129488;</h3>
                            <div class="subheading mb-3">Natural Language Processing, Web Scraping</div>
                            <p>
                              In this project, I develop an original machine learning (ML) algorithm that classifies the conclusions of fact-checking articles (paired with other data, such as the topic, source, etc.) as one of the following labels: false, misleading, true, or unproven. I was provided with a train set of ~6,000 examples and an unlabeled test set of ~700 examples. My objective was to train a model on the train set and predict the labels of the examples in the test set, which would be evaluated for accuracy on Kaggle. The two major obstacles in the task were the heavy imbalance of labeling (mostly 0’s), and the need for feature engineering, as very little information was provided in the datasets. As a result, I was able to extract more features by requesting the HTML pages of each article in the dataset, then develop an algorithm (I call <em>switching</em>) that would primarily learn on these new features.
                            </p>
                            <p><a href="work/smm.pdf" target="_blank">Report</a> &nbsp; · &nbsp; <a href="">Github</a></p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">November 2021 - December 2021</span></div>
                    </div>

                    <div id="suri-presentation" class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                          <img style="max-height:250px;max-width:90%;margin: 0px 0px 10px 0px;"src="assets/img/suri.png">
                            <h3 class="mb-0">Robustness of a Tunable Loss Function Family on Corrupted Datasets &#x1F3DE; &#x1F512;</h3>
                            <div class="subheading mb-3">Image Classification, Robust Loss Functions, Data Augmentation</div>
                            <p>
                              A very important assumption in image classification is that the train and test sets are independent and identically distributed (i.i.d.); when this assumption does not hold– whether on the prior (image distribution shift) or posterior (label noise) side– deep learning models noticeably decline in their performance. In this presentation, I discuss the use of two methods– data augmentation and robust loss functions– that address the problems of test-time
                              feature distribution shifts and train-time noisy labeling, respectively. Specifically, I demonstrate the effectiveness of <em>AugLoss</em> (a data augmentation technique) and <em>alpha loss</em> (a robust loss function) on corrupted versions of the CIFAR-10/100 datasets. Lastly, I combine the two methods and show that this combination achieves even better performance when both the test features and train labels are corrupted.
                            </p>
                            <p><a href="work/suri.pdf" target="_blank">Presentation</a> &nbsp; · &nbsp; <a href="">Github</a></p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">May 2021 - July 2021</span></div>
                    </div>

                    <div id="travel-blog" class="d-flex flex-column flex-md-row justify-content-between mb-5">
                        <div class="flex-grow-1">
                          <img style="max-height:250px;max-width:90%;margin: 0px 0px 10px 0px;"src="assets/img/nt.png">
                            <h3 class="mb-0">Full-Stack Development of a Responsive Travel Blog AND Admin Portal &#x1F6E9; &#x1F30D;</h3>
                            <div class="subheading mb-3">Web Development, Web Design</div>
                            <p>
                              In this project, I designed and developed a travel blog + admin interface from scratch. The travel blog is fully responsive and features a variety of user-triggered animations, such as handwritten text, photos, and moving backgrounds.
                              The front end was implemented with HTML, CSS, and vanilla JavaScript. Additionally, the admin interface is password-protected and allows the blogger to post content (automatic image compression), manage the site layout, and send emails to subscribers; these back end features were primarily implemented with PHP.
                              Lastly, I used SQL with PHP MyAdmin to (1) create a newsletter database that collects subscribers’ names, emails, and other useful information, and (2) create an automated traffic monitoring service that allows the blogger to evaluate the performance of the site.
                            </p>
                            <p><a href="https://nicoletravels.com" target="_blank">Website</a> &nbsp; · &nbsp; <a href="">Github</a></p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">September 2020 - July 2021</span></div>
                    </div>

                    <div id="hypothetest" class="d-flex flex-column flex-md-row justify-content-between">
                        <div class="flex-grow-1">
                          <img style="max-height:250px;max-width:90%;margin: 0px 0px 10px 0px;"src="assets/img/hypothetest.png">
                            <h3 class="mb-0"><em>Hypothetest:</em> An interactive storyline generator for two-sample hypothesis tests 	&#x270F; &#x1F4C8;</h3>
                            <div class="subheading mb-3">Hypothesis Testing, Web Development</div>
                            <p>
                              As a probability & statistics TA, I designed and developed a website that generates a customized write-up of the student's two-sample hypothesis test problem, including all calculation and explanation typically found in a statistics textbook. The design includes a simple but responsive layout, implemented with HTML and CSS. The functionality includes the navigation of a built-in storyboard, implemented with vanilla JavaScript. The MathJax JS library is used to generate the mathematical notation and equations, and the HighCharts JS library is used to dynamically graph the distributions.
                            </p>
                            <p><a href="https://kotstot6.github.io/Hypothetest/" target="_blank">Website</a> &nbsp; · &nbsp; <a href="https://github.com/kotstot6/Hypothetest/" target="_blank">Github</a></p>
                        </div>
                        <div class="flex-shrink-0"><span class="text-primary">November 2020 - December 2020</span></div>
                    </div>

                </div>
            </section>
            <hr class="m-0" />
            <!-- Skills-->
            <section class="resume-section" id="skills">
                <div class="resume-section-content flex-grow-1">
                    <h2 class="mb-5">Skills &#x1F939;</h2>
                    <div class="subheading mb-3">Programming Overview &#x1F50D;</div>
                    <ul class="list-inline dev-icons">
                        <li class="list-inline-item"><i class="fab fa-python"></i></li>
                        <li class="list-inline-item"><i class="fab fa-html5"></i></li>
                        <li class="list-inline-item"><i class="fab fa-css3-alt"></i></li>
                        <li class="list-inline-item"><i class="fab fa-js-square"></i></li>
                        <li class="list-inline-item"><i class="fab fa-node-js"></i></li>
                        <li class="list-inline-item"><i class="fab fa-npm"></i></li>
                        <li class="list-inline-item"><i class="fab fa-php"></i></li>
                        <li class="list-inline-item"><i class="fab fa-git"></i></li>
                    </ul>
                    <div class="subheading mb-3">Deep Learning &#x1F578;</div>
                    <ul class="fa-ul mb-3">
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            <b>Libraries:</b> PyTorch, Tensorflow, NumPy, Ray, Kubeflow
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            <b>Fields:</b> Computer vision, Natural language processing, Signal processing
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            <b>Tasks:</b> Domain adaptation, Image classification, Image generation, Image deblurring, Image-to-image translation, Time-series forecasting, Text classification, Named entity recognition, Recommendation systems, Compressive sensing, Clustering, Dimensionality reduction
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            <b>Architectures:</b> Dense neural nets (MLPs), CNNs, Wide and deep nets, Residual nets, U-Nets, RNNs (LSTMs, Bi-LSTMs), GANs, VAEs, RBMs, Text transformers (BERT, XLNet, GPT), Vision transformers, Diffusion models
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-check"></i></span>
                            <b>Datasets:</b> MNIST, Stacked MNIST, Fashion MNIST, MNIST-M, MNIST-C, CIFAR-10/100, CIFAR-10/100-C, CIFAR-10/100-N, Tiny ImageNet, ImageNet, Celeb-A, LSUN, IMDB, MovieLens, Netflix Prize, Spotify Million Playlist
                        </li>
                    </ul>
                    <div class="subheading mb-3">Machine Learning &#x1F916;</div>
                    <ul class="fa-ul mb-3">
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          <b>Libraries:</b> Scikit-Learn, NumPy, Pandas, Pyspark, SparkML, nltk, MATLAB built-ins
                      </li>
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          <b>Tasks:</b> Classification, Regression, Clustering, Association, Recommendation
                      </li>
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          <b>Models:</b> Perceptron/Linear regression, SVMs, KNN, Decision trees, Random Forest, Gradient boosting (XGBoost, LightGBM, CatBoost), Naive Bayes, Matrix factorization, Content-based/collaborative filtering, PCA, SVD, K-Means clustering, DBSCAN, Hierarchical clustering, t-SNE
                      </li>
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          <b>Courses:</b> Statistical Machine Learning, ML Security & Fairness
                      </li>
                    </ul>
                    <div class="subheading mb-3">Data Mining &#x26CF;</div>
                    <ul class="fa-ul mb-3">
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          <b>Python Libraries:</b> BeautifulSoup, Selenium, requests, nltk, Pandas, Pyspark
                      </li>
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          <b>Tasks:</b> Community detection (CPM, Spectral, Modularity), Web ranking (Katz, PageRank), Association rule mining (Apriori), Data transformation (TF-IDF, Word2Vec, GloVe)
                      </li>
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          <b>Courses:</b> Data Mining, Semantic Web Mining, Social Media Mining
                      </li>
                    </ul>
                    <div class="subheading mb-3">Data Visualization &#x1F4CA;</div>
                    <ul class="fa-ul mb-3">
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          <b>Python Libraries:</b> Matplotlib, Seaborn
                      </li>
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          <b>JS Libraries:</b> D3, Leaflet, HighCharts
                      </li>
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          <b>Other tools:</b> Tableau, Power BI
                      </li>
                    </ul>
                    <div class="subheading mb-3">Web Development &#x1F4BB;</div>
                    <ul class="fa-ul mb-3">
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          <b>Client side:</b> HTML, CSS, JavaScript, Pyodide, MathJax
                      </li>
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          <b>Server side:</b> PHP, SQL, MySQL (GCP, AWS), BigQuery, Node.js, Flask
                      </li>
                    </ul>
                    <div class="subheading mb-3">Miscellaneous Skills &#x1F31F;</div>
                    <ul class="fa-ul mb-0">
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          <b>Languages:</b> Java, C/C++, MATLAB, Bash, Git
                      </li>
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          An extensive mathematical background up to the undergraduate level, including advanced calculus, linear algebra, graph theory, and scientific computing
                      </li>
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          Experience in academic writing, specifically with LaTeX
                      </li>
                      <li>
                          <span class="fa-li"><i class="fas fa-check"></i></span>
                          Proficiency in research computing & shared cluster environments with SLURM
                      </li>
                    </ul>
                </div>
            </section>
            <hr class="m-0" />
            <!-- Awards-->
            <section class="resume-section" id="awards">
                <div class="resume-section-content">
                    <h2 class="mb-5">Awards &#x1F947;</h2>
                    <ul class="fa-ul mb-0">
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            <b>August 2022:</b> Awarded the 1st place prize of $7500 for winning the <em>2022 Wells Fargo Campus Analytics Challenge</em>, a nationwide ML competition prompting college students to use state-of-the-art natural language processing (NLP) techniques to develop a transaction categorizer trained with their data. My submission named <a class="scroll-link" href="#wells-fargo"><em>Building Robust & Accurate Transaction Classifiers with Deep Transfer Learning</em>
                              <svg class="bi bi-arrow-up-right-square" width="15px" height="15px" viewBox="0 0 16 16" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
                                <path fill-rule="evenodd" d="M14 1H2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V2a1 1 0 0 0-1-1zM2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2z"></path>
                                <path fill-rule="evenodd" d="M10.5 5h-4a.5.5 0 0 0 0 1h2.793l-4.147 4.146a.5.5 0 0 0 .708.708L10 6.707V9.5a.5.5 0 0 0 1 0v-4a.5.5 0 0 0-.5-.5z"></path>
                              </svg>
                            </a> is protected via NDA, so the paper and repository will not be publicly available until August 2023.
                        </li>
                        <li>
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            <b>June 2022:</b> My co-authored paper <a class="scroll-link" href="#augloss"><em>AugLoss: A Learning Methodology for Real-World Dataset Corruption</em>
                              <svg class="bi bi-arrow-up-right-square" width="15px" height="15px" viewBox="0 0 16 16" fill="currentColor" xmlns="http://www.w3.org/2000/svg">
                                <path fill-rule="evenodd" d="M14 1H2a1 1 0 0 0-1 1v12a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V2a1 1 0 0 0-1-1zM2 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H2z"></path>
                                <path fill-rule="evenodd" d="M10.5 5h-4a.5.5 0 0 0 0 1h2.793l-4.147 4.146a.5.5 0 0 0 .708.708L10 6.707V9.5a.5.5 0 0 0 1 0v-4a.5.5 0 0 0-.5-.5z"></path>
                              </svg>
                            </a> was one of 40 submissions accepted into the <em>Principles of Distribution Shift workshop at the 2022 International Conference on Machine Learning (ICML)</em>. In July 2022, I presented the paper at the ICML workshop in Baltimore, Maryland.
                        </li>
                        <li>
                          <img style="max-height:300px;max-width:90%;margin: 20px 0px;"src="assets/img/pods.jpeg">
                        </li>
                        <li id="phi-beta-kappa">
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            <b>April 2022:</b> Selected to join ASU's chapter of <em>Phi Beta Kappa</em>, the nation's oldest and most prestigious honor society for the liberal arts and sciences. Fewer than 2% of ASU's College of Liberal Arts & Sciences (CLAS) graduates are selected to Phi Beta Kappa annually. Inducted on April 29th, 2022.
                        </li>
                        <li id="wexler-dinner">
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            <b>April 2022:</b> Selected to attend the sixth annual <em>Jonathan D. and Helen Wexler Mathematical Sciences Senior Dinner</em>. Only a handful of outstanding seniors in the School of Mathematical and Statistical Sciences (SMSS) are selected annually.
                        </li>
                        <li id="cse-scholarship">
                            <span class="fa-li"><i class="fas fa-trophy text-warning"></i></span>
                            <b>December 2021:</b> Selected to receive the <em>2021-2022 Dr. William E. Lewis Excellence in Computer Science Engineering Scholarship</em> with the approximate amount of $6199. One student in the Fulton Schools of Engineering is selected to receive this scholarship annually.
                        </li>
                    </ul>
                </div>
            </section>
        </div>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
